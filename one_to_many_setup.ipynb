{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "one_to_many_setup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "352af022d25847b8b087cbe855bddf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f39035aae3904d439ab622f4568e33bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c80c94a29614f20bbdea954b1c0f3a1",
              "IPY_MODEL_241bf9113dff431e8a9c89a6821dbb37"
            ]
          }
        },
        "f39035aae3904d439ab622f4568e33bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c80c94a29614f20bbdea954b1c0f3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a1e6e421730499aa013f2451d0df195",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b6bd2cb0bfd4a518a4cca0c2319636d"
          }
        },
        "241bf9113dff431e8a9c89a6821dbb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_766c9f5a4d4645ff8abf6e6e206f5eb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 320kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59e928c18d1540428534e63c72fece68"
          }
        },
        "5a1e6e421730499aa013f2451d0df195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b6bd2cb0bfd4a518a4cca0c2319636d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "766c9f5a4d4645ff8abf6e6e206f5eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59e928c18d1540428534e63c72fece68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2acab40798f34644aa0aa548f4127f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3629a6f96d6c420eb898a6140e400040",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b3e54534b1840bba0f400e640f16227",
              "IPY_MODEL_5f7c7eece13c49ef82104e772d8197ed"
            ]
          }
        },
        "3629a6f96d6c420eb898a6140e400040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b3e54534b1840bba0f400e640f16227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bb93703f49c144e9b68f551fa2745293",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1c6553958794836bf6db2ae79622ede"
          }
        },
        "5f7c7eece13c49ef82104e772d8197ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fb4d4bf535c493cbbda968c1277489e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 147B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d0a05d3a1634bc491137d7263033849"
          }
        },
        "bb93703f49c144e9b68f551fa2745293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1c6553958794836bf6db2ae79622ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fb4d4bf535c493cbbda968c1277489e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d0a05d3a1634bc491137d7263033849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c39d3dcde7c94d8882dfb3da78e92f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d99f643b336480e881c5f3c41f15bf9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cd8e22da2664445aa5724570ce2f862",
              "IPY_MODEL_30058d079e334bfc8902aa65dfd09e3a"
            ]
          }
        },
        "0d99f643b336480e881c5f3c41f15bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cd8e22da2664445aa5724570ce2f862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8da2270b0c0141b5b8462bb1b982ce9b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d6d3461308943bb8e21e11c7e50a3df"
          }
        },
        "30058d079e334bfc8902aa65dfd09e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce43ac47375d44fda20bc6dcb3641a8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 3.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_678384333d4646a2b3d23469eeb577db"
          }
        },
        "8da2270b0c0141b5b8462bb1b982ce9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d6d3461308943bb8e21e11c7e50a3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce43ac47375d44fda20bc6dcb3641a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "678384333d4646a2b3d23469eeb577db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee542a9d97d54128b141fb60e73beef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a113a8ef6dbb49f8828908e987a09734",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b33b37e08d54743a67140b32d7840e7",
              "IPY_MODEL_975f3c7194ca4894ba6229949581083d"
            ]
          }
        },
        "a113a8ef6dbb49f8828908e987a09734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b33b37e08d54743a67140b32d7840e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f34ea601aa8c49b58e52b415b0b5f027",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68884d9b56f445d8907915760b1284ef"
          }
        },
        "975f3c7194ca4894ba6229949581083d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a17dadaa23c34f4aa053b83fd9078586",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 2.37kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_156e8840db364002ae0258ec2502bb25"
          }
        },
        "f34ea601aa8c49b58e52b415b0b5f027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68884d9b56f445d8907915760b1284ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a17dadaa23c34f4aa053b83fd9078586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "156e8840db364002ae0258ec2502bb25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcfa19907be040a7a07105b3236a8a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e692e23b1186407f85a3456aa0c7aed9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b0f24a4f10ef401cb36373d0355a162d",
              "IPY_MODEL_67cfc84a22314572bc4c7bb85815b955"
            ]
          }
        },
        "e692e23b1186407f85a3456aa0c7aed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0f24a4f10ef401cb36373d0355a162d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d11e1dc3822f4f759c5f8c2513845b8a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef28085117a04441b54549c7603d2329"
          }
        },
        "67cfc84a22314572bc4c7bb85815b955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e84c4988eaf41ec8c3d381ab1026217",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 34.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbb8aae70ffc4f14bff8667e4648b9cd"
          }
        },
        "d11e1dc3822f4f759c5f8c2513845b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef28085117a04441b54549c7603d2329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e84c4988eaf41ec8c3d381ab1026217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbb8aae70ffc4f14bff8667e4648b9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SCTeXzBcJuG",
        "outputId": "cf7bb88d-ee58-4253-a0d9-4d0aa90342bd"
      },
      "source": [
        "'''\n",
        "mount google drive\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULR4MQm-d3E3",
        "outputId": "a64e1bab-2627-4f6f-e8ed-41e289f3a0b4"
      },
      "source": [
        "'''\n",
        "install required libraries\n",
        "'''\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.5MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBBuSRg6d5sH",
        "outputId": "64afa1da-c06b-4f64-ec66-1eb17a642ee7"
      },
      "source": [
        "'''\n",
        "import required packages\n",
        "'''\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import itertools\n",
        "import pickle\n",
        "import glob\n",
        "\n",
        "from queue import PriorityQueue\n",
        "import operator\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import transformers\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords  \n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blgpDRNwd8m5"
      },
      "source": [
        "'''\n",
        "configuration for deterministic results with multiple run\n",
        "'''\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) \n",
        "\n",
        "np.random.seed(seed)  \n",
        "random.seed(seed) \n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GfsPQhId_w3"
      },
      "source": [
        "'''\n",
        "pandas configuration for showing complete content of record\n",
        "'''\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 2000)\n",
        "pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Pe2ewPHIoHx",
        "outputId": "9527b0eb-a764-4791-f97b-4c0d696f4b7e"
      },
      "source": [
        "'''\n",
        "load news data and show some sample \n",
        "'''\n",
        "data_path='/content/gdrive/My Drive/Capstone_Project/Data/News_Data/news_article_with_sim_score.df'\n",
        "article_df=pd.read_pickle(data_path)\n",
        "no_of_headlines=[len(similar_headlines) for similar_headlines in article_df['similar_headline'].tolist()]\n",
        "print('max no of similar headlines: ',max(no_of_headlines))\n",
        "print('min no of similar headlines: ',min(no_of_headlines))\n",
        "print('article_df shape:',article_df.shape)\n",
        "article_df.sample(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max no of similar headlines:  13\n",
            "min no of similar headlines:  0\n",
            "article_df shape: (3000, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_url</th>\n",
              "      <th>headline</th>\n",
              "      <th>content</th>\n",
              "      <th>author</th>\n",
              "      <th>published_date</th>\n",
              "      <th>read_more_source</th>\n",
              "      <th>similar_headline</th>\n",
              "      <th>similar_headline_url</th>\n",
              "      <th>similarity_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>https://inshorts.com/en/news/foot-of-missing-businesswoman-who-stole-â‚¹74cr-from-clients-found-on-aus-beach-1614333830092</td>\n",
              "      <td>Foot of missing businesswoman who stole â‚¹74cr from clients found on Aus beach</td>\n",
              "      <td>Australian police has said that campers have found the decomposed foot of missing businesswoman Melissa Caddick on a beach. Caddick, who allegedly stole A$13 million (over â‚¹74 crore) from her clients, disappeared on November 12 last year after federal police raided her home in Sydney. \"She may have taken her own life,\" police added.</td>\n",
              "      <td>None</td>\n",
              "      <td>2021-02-26T10:03:50.000Z</td>\n",
              "      <td>Daily Mail</td>\n",
              "      <td>[Melissa Caddick: Missing fraud suspect's foot found on Australian beach, Melissa Caddick: remains of missing businesswoman found months after disappearance, Melissa Caddick dead, police confirm, after campers find her foot on NSW South Coast, Remains of missing businesswoman and 'conwoman' Melissa Caddick have been found, NSW Health In Australia Orders Radiology Solution From Sectra For Enterprise Access To Images, Sexy Croc &amp;dash Entry #1372 &amp;dash Data Clustering Contest]</td>\n",
              "      <td>[https://www.bbc.com/news/world-australia-56205519, https://www.theguardian.com/australia-news/2021/feb/26/melissa-caddick-missing-financial-adviser-found-dead-months-after-disappearance, https://www.abc.net.au/news/2021-02-26/melissa-caddick-found-dead/13195242, https://www.dailymail.co.uk/news/article-9301259/Remains-missing-businesswoman-conwoman-Melissa-Caddick-found.html, https://www.medicalbuyer.co.in/nsw-health-in-australia-orders-radiology-solution-from-sectra-for-enterprise-access-to-images/, https://entry1372-dcround2.usercontent.dev/20200529/categories/en/economy.html]</td>\n",
              "      <td>[0.58, 0.51, 0.34, 0.49, 0.19, 0.16]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1190</th>\n",
              "      <td>https://inshorts.com/en/news/trumps-gab-account-compromised-as-hackers-target-platform-1614608033197</td>\n",
              "      <td>Trump's Gab account compromised as hackers target platform</td>\n",
              "      <td>Former US President Donald Trump's Gab account was compromised along with the social network Gab CEO Andrew Torba's account. Torba revealed that the platform is being attacked by hackers who had earlier targeted law enforcement officers. According to Wired, around 70 gigabytes of Gab data representing over 40 million posts has been stolen and includes passwords, group passwords and messages.</td>\n",
              "      <td>None</td>\n",
              "      <td>2021-03-01T14:13:53.000Z</td>\n",
              "      <td>Business Insider India</td>\n",
              "      <td>[Far-right social media Gab hacked, Trump's account targeted, Gab confirms it was hacked, Trump and Gab CEO accounts compromised during large-scale hack of alternative social media platform, Gab Hack Reveals Passwords And Private Messages, Hacktivists Attack Controversial Christian Conservative Social Media Site Gab, Leak 70 Gigabytes of Hacked Data Including Private Messages and Passwords, Gab: hack gives unprecedented look into platform used by far right, Gab Founder Andrew Torba Says Platform Was Hacked By Far-Left Activists : US : Christianity Daily, US Right-Wing Platform Gab Acknowledges it Was Hacked, Passwords, Private Posts Exposed in Hack of Gab Social Network]</td>\n",
              "      <td>[https://www.jpost.com/international/far-right-social-media-gab-hacked-trumps-account-targeted-660790, https://www.securitymagazine.com/articles/94733-gab-confirms-it-was-hacked, https://www.coloradopolitics.com/news/trump-and-gab-ceo-accounts-compromised-during-large-scale-hack-of-alternative-social-media-platform/article_379f06da-eb18-5226-b920-0833a591345f.html, https://www.forbes.com/sites/emmawoollacott/2021/03/02/gab-hack-reveals-passwords-and-private-posts/, https://www.cpomagazine.com/cyber-security/hacktivists-attack-controversial-christian-conservative-social-media-site-gab-leak-70-gigabytes-of-hacked-data-including-private-messages-and-passwords/, https://www.theguardian.com/world/2021/mar/11/gab-hack-neo-nazis-qanon-conspiracy-theories, http://www.christianitydaily.com/articles/11022/20210303/gab-founder-andrew-torba-says-platform-was-hacked-by-far-left-activists.htm, https://www.securityweek.com/us-right-wing-platform-gab-acknowledges-it-was-hacked, https://threatpost.com/hacktivists-gab-posts-passwords/164360/]</td>\n",
              "      <td>[0.76, 0.66, 0.86, 0.54, 0.47, 0.59, 0.43, 0.44, 0.54]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                   article_url                                                                       headline                                                                                                                                                                                                                                                                                                                                                                                                     content author            published_date        read_more_source                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         similar_headline  \\\n",
              "1801  https://inshorts.com/en/news/foot-of-missing-businesswoman-who-stole-â‚¹74cr-from-clients-found-on-aus-beach-1614333830092  Foot of missing businesswoman who stole â‚¹74cr from clients found on Aus beach                                                              Australian police has said that campers have found the decomposed foot of missing businesswoman Melissa Caddick on a beach. Caddick, who allegedly stole A$13 million (over â‚¹74 crore) from her clients, disappeared on November 12 last year after federal police raided her home in Sydney. \"She may have taken her own life,\" police added.   None  2021-02-26T10:03:50.000Z              Daily Mail                                                                                                                                                                                                           [Melissa Caddick: Missing fraud suspect's foot found on Australian beach, Melissa Caddick: remains of missing businesswoman found months after disappearance, Melissa Caddick dead, police confirm, after campers find her foot on NSW South Coast, Remains of missing businesswoman and 'conwoman' Melissa Caddick have been found, NSW Health In Australia Orders Radiology Solution From Sectra For Enterprise Access To Images, Sexy Croc &dash Entry #1372 &dash Data Clustering Contest]   \n",
              "1190                      https://inshorts.com/en/news/trumps-gab-account-compromised-as-hackers-target-platform-1614608033197                     Trump's Gab account compromised as hackers target platform  Former US President Donald Trump's Gab account was compromised along with the social network Gab CEO Andrew Torba's account. Torba revealed that the platform is being attacked by hackers who had earlier targeted law enforcement officers. According to Wired, around 70 gigabytes of Gab data representing over 40 million posts has been stolen and includes passwords, group passwords and messages.   None  2021-03-01T14:13:53.000Z  Business Insider India  [Far-right social media Gab hacked, Trump's account targeted, Gab confirms it was hacked, Trump and Gab CEO accounts compromised during large-scale hack of alternative social media platform, Gab Hack Reveals Passwords And Private Messages, Hacktivists Attack Controversial Christian Conservative Social Media Site Gab, Leak 70 Gigabytes of Hacked Data Including Private Messages and Passwords, Gab: hack gives unprecedented look into platform used by far right, Gab Founder Andrew Torba Says Platform Was Hacked By Far-Left Activists : US : Christianity Daily, US Right-Wing Platform Gab Acknowledges it Was Hacked, Passwords, Private Posts Exposed in Hack of Gab Social Network]   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  similar_headline_url                                       similarity_scores  \n",
              "1801                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [https://www.bbc.com/news/world-australia-56205519, https://www.theguardian.com/australia-news/2021/feb/26/melissa-caddick-missing-financial-adviser-found-dead-months-after-disappearance, https://www.abc.net.au/news/2021-02-26/melissa-caddick-found-dead/13195242, https://www.dailymail.co.uk/news/article-9301259/Remains-missing-businesswoman-conwoman-Melissa-Caddick-found.html, https://www.medicalbuyer.co.in/nsw-health-in-australia-orders-radiology-solution-from-sectra-for-enterprise-access-to-images/, https://entry1372-dcround2.usercontent.dev/20200529/categories/en/economy.html]                    [0.58, 0.51, 0.34, 0.49, 0.19, 0.16]  \n",
              "1190  [https://www.jpost.com/international/far-right-social-media-gab-hacked-trumps-account-targeted-660790, https://www.securitymagazine.com/articles/94733-gab-confirms-it-was-hacked, https://www.coloradopolitics.com/news/trump-and-gab-ceo-accounts-compromised-during-large-scale-hack-of-alternative-social-media-platform/article_379f06da-eb18-5226-b920-0833a591345f.html, https://www.forbes.com/sites/emmawoollacott/2021/03/02/gab-hack-reveals-passwords-and-private-posts/, https://www.cpomagazine.com/cyber-security/hacktivists-attack-controversial-christian-conservative-social-media-site-gab-leak-70-gigabytes-of-hacked-data-including-private-messages-and-passwords/, https://www.theguardian.com/world/2021/mar/11/gab-hack-neo-nazis-qanon-conspiracy-theories, http://www.christianitydaily.com/articles/11022/20210303/gab-founder-andrew-torba-says-platform-was-hacked-by-far-left-activists.htm, https://www.securityweek.com/us-right-wing-platform-gab-acknowledges-it-was-hacked, https://threatpost.com/hacktivists-gab-posts-passwords/164360/]  [0.76, 0.66, 0.86, 0.54, 0.47, 0.59, 0.43, 0.44, 0.54]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHvSrrkxNeQA"
      },
      "source": [
        "contents=[]\n",
        "target_headlines_1=[]\n",
        "target_headlines_2=[]\n",
        "target_headlines_3=[]\n",
        "similarity_scores_threshold=0.50\n",
        "for index, row in article_df.iterrows():\n",
        "  similarity_scores=row['similarity_scores']\n",
        "  #print(similarity_scores)\n",
        "  #print(similar_headlines)\n",
        "  sorted_index=list(np.argsort(similarity_scores)) # in ascending order\n",
        "  sorted_index.reverse() # in descending order\n",
        "  if len(sorted_index)>=2:\n",
        "    second_highest_sim_score=similarity_scores[sorted_index[1]]\n",
        "    #print(second_highest_sim_score)\n",
        "    if (second_highest_sim_score >= similarity_scores_threshold):\n",
        "      target_headlines_1.append(row['headline'])\n",
        "      similar_headlines=row['similar_headline']\n",
        "      target_headlines_2.append(similar_headlines[sorted_index[0]]) # first best similar\n",
        "      target_headlines_3.append(similar_headlines[sorted_index[1]]) # second best similar\n",
        "      contents.append(row['content'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-yzOdo4sGYh",
        "outputId": "86935e52-bbba-4f00-9dea-5494f106112c"
      },
      "source": [
        "#sample record\n",
        "print('news-summary: ',contents[0])\n",
        "print('headlines1: ',target_headlines_1[0])\n",
        "print('headlines2: ',target_headlines_2[0])\n",
        "print('headlines3: ',target_headlines_3[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "news-summary:  Taking to Instagram on Saturday, Arjun Kapoor posted a picture of himself with Janhvi Kapoor to wish the actress on her 24th birthday. In the picture, Arjun can be seen walking ahead while holding his sister's hand. \"Happy birthday Janhvi...I can't promise much except like this picture you shall always have my support & hand wherever you go,\" Arjun wrote.\n",
            "headlines1:  You shall always have my support: Arjun Kapoor on Janhvi's b'day\n",
            "headlines2:  'You shall always have my support': Arjun Kapoor pens heart-warming birthday note for Janhvi\n",
            "headlines3:  \"You will always have my support,\" Arjun Kapoor writes a heartfelt birthday note for Janhvi Kapoor.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt-aPPiKtKlH",
        "outputId": "5a4059f1-8aa2-44fa-ffba-d5f6aa09522f"
      },
      "source": [
        "'''\n",
        "decide threshold for min and max no-of-word-token in headline \n",
        "'''\n",
        "headlines = [headline for headline in target_headlines_1] + [headline for headline in target_headlines_2] + [headline for headline in target_headlines_3]\n",
        "headline_len=[len(headline.split(' '))for headline in headlines]\n",
        "print('5th percentile length: ',np.quantile(headline_len, 0.05))\n",
        "print('25th percentile length: ',np.quantile(headline_len, 0.25))\n",
        "print('50th percentile length: ',np.quantile(headline_len, 0.50))\n",
        "print('75th percentile length: ',np.quantile(headline_len, 0.75))\n",
        "print('95th percentile length: ',np.quantile(headline_len, 0.95))\n",
        "print('99th percentile length: ',np.quantile(headline_len, 0.99))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5th percentile length:  8.0\n",
            "25th percentile length:  10.0\n",
            "50th percentile length:  12.0\n",
            "75th percentile length:  14.0\n",
            "95th percentile length:  18.0\n",
            "99th percentile length:  22.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgR962aFuAdX",
        "outputId": "81ef5110-72a6-43f7-b337-cfafe1da5e42"
      },
      "source": [
        "'''\n",
        "creating summary-headline pair and then randomly shuffle them\n",
        "'''\n",
        "summary_headline_pairs=list(zip(contents,target_headlines_1, target_headlines_2, target_headlines_3))\n",
        "random.shuffle(summary_headline_pairs)\n",
        "len(summary_headline_pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRbh4FTduNZS"
      },
      "source": [
        "'''\n",
        "get train and test dataset\n",
        "'''\n",
        "train_summary_headline_pairs=summary_headline_pairs[0:2000]\n",
        "#train_summary_headline_pairs=summary_headline_pairs[0:100]#just for faster testing if code flow is working fine\n",
        "test_summary_headline_pairs=summary_headline_pairs[2000:]\n",
        "no_of_training_records=len(train_summary_headline_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROAdpWPb0zuP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "352af022d25847b8b087cbe855bddf45",
            "f39035aae3904d439ab622f4568e33bf",
            "5c80c94a29614f20bbdea954b1c0f3a1",
            "241bf9113dff431e8a9c89a6821dbb37",
            "5a1e6e421730499aa013f2451d0df195",
            "9b6bd2cb0bfd4a518a4cca0c2319636d",
            "766c9f5a4d4645ff8abf6e6e206f5eb1",
            "59e928c18d1540428534e63c72fece68",
            "2acab40798f34644aa0aa548f4127f34",
            "3629a6f96d6c420eb898a6140e400040",
            "2b3e54534b1840bba0f400e640f16227",
            "5f7c7eece13c49ef82104e772d8197ed",
            "bb93703f49c144e9b68f551fa2745293",
            "e1c6553958794836bf6db2ae79622ede",
            "6fb4d4bf535c493cbbda968c1277489e",
            "3d0a05d3a1634bc491137d7263033849",
            "c39d3dcde7c94d8882dfb3da78e92f3a",
            "0d99f643b336480e881c5f3c41f15bf9",
            "1cd8e22da2664445aa5724570ce2f862",
            "30058d079e334bfc8902aa65dfd09e3a",
            "8da2270b0c0141b5b8462bb1b982ce9b",
            "5d6d3461308943bb8e21e11c7e50a3df",
            "ce43ac47375d44fda20bc6dcb3641a8d",
            "678384333d4646a2b3d23469eeb577db",
            "ee542a9d97d54128b141fb60e73beef4",
            "a113a8ef6dbb49f8828908e987a09734",
            "4b33b37e08d54743a67140b32d7840e7",
            "975f3c7194ca4894ba6229949581083d",
            "f34ea601aa8c49b58e52b415b0b5f027",
            "68884d9b56f445d8907915760b1284ef",
            "a17dadaa23c34f4aa053b83fd9078586",
            "156e8840db364002ae0258ec2502bb25",
            "bcfa19907be040a7a07105b3236a8a3e",
            "e692e23b1186407f85a3456aa0c7aed9",
            "b0f24a4f10ef401cb36373d0355a162d",
            "67cfc84a22314572bc4c7bb85815b955",
            "d11e1dc3822f4f759c5f8c2513845b8a",
            "ef28085117a04441b54549c7603d2329",
            "2e84c4988eaf41ec8c3d381ab1026217",
            "fbb8aae70ffc4f14bff8667e4648b9cd"
          ]
        },
        "id": "FvQY9dOguozn",
        "outputId": "155337d3-6a00-44f1-d909-ab9d7246a853"
      },
      "source": [
        "'''\n",
        "load Bert-Model and Tokeninzer using predefined weights\n",
        "distilbert-base-uncased' model is uncased: it does not make a difference between english and English. \n",
        "'''\n",
        "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, \"bert-base-uncased\")# 'distilbert-base-uncased'\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "352af022d25847b8b087cbe855bddf45",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2acab40798f34644aa0aa548f4127f34",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c39d3dcde7c94d8882dfb3da78e92f3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee542a9d97d54128b141fb60e73beef4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcfa19907be040a7a07105b3236a8a3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLGesjBuu7Xo",
        "outputId": "c77d81f3-1bdf-408a-b7c3-d0432333fbad"
      },
      "source": [
        "'''\n",
        "initialize BOS and EOS token\n",
        "'''\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "print('SOS token id: ',tokenizer.bos_token_id)\n",
        "print('EOS token id: ',tokenizer.eos_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SOS token id:  101\n",
            "EOS token id:  102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw8KHRYtItQq"
      },
      "source": [
        "'''\n",
        "tokenize news summary and headline\n",
        "'''\n",
        "max_encoder_len=125\n",
        "max_decoder_len=40 \n",
        "tokenized_summaries = [tokenizer(summary, padding=\"max_length\", truncation=True, max_length=max_encoder_len) for summary in contents]\n",
        "tokenized_headlines_1 = [tokenizer(target_headlines, padding=\"max_length\", truncation=True, max_length=max_decoder_len) for target_headlines in target_headlines_1]\n",
        "tokenized_headlines_2 = [tokenizer(target_headlines, padding=\"max_length\", truncation=True, max_length=max_decoder_len) for target_headlines in target_headlines_2]\n",
        "tokenized_headlines_3 = [tokenizer(target_headlines, padding=\"max_length\", truncation=True, max_length=max_decoder_len) for target_headlines in target_headlines_3]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW1d0iddJD2-"
      },
      "source": [
        "summary_lengths = [len(tokenized_summary.input_ids) for tokenized_summary in tokenized_summaries]\n",
        "headline_lengths_1 = [len(tokenized_headline.input_ids) for tokenized_headline in tokenized_headlines_1]\n",
        "headline_lengths_2 = [len(tokenized_headline.input_ids) for tokenized_headline in tokenized_headlines_2]\n",
        "headline_lengths_3 = [len(tokenized_headline.input_ids) for tokenized_headline in tokenized_headlines_3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYb8B0pGJKai",
        "outputId": "b8d06966-a467-4730-a995-d5d9f5f51980"
      },
      "source": [
        "print('summary_lengths_max: ',max(summary_lengths))\n",
        "print('headline1_lengths_max: ',max(headline_lengths_1))\n",
        "print('headline2_lengths_max: ',max(headline_lengths_2))\n",
        "print('headline3_lengths_max: ',max(headline_lengths_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "summary_lengths_max:  125\n",
            "headline1_lengths_max:  32\n",
            "headline2_lengths_max:  173\n",
            "headline3_lengths_max:  51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVdMyu02u_gB"
      },
      "source": [
        "'''\n",
        "instance of class Batch_Data represent input to the encoder decoder model for a batch\n",
        "'''\n",
        "class Batch_Data:\n",
        "  def __init__(self, batch_ip_vector, batch_ip_length, batch_op_vector_1, batch_op_vector_2, batch_op_vector_3, batch_op_token_idxs_1, batch_op_token_idxs_2, \n",
        "               batch_op_token_idxs_3, batch_mask_1, batch_mask_2, batch_mask_3):\n",
        "    self.batch_ip_vector=batch_ip_vector\n",
        "    self.batch_ip_length=batch_ip_length\n",
        "    self.batch_op_vector_1=batch_op_vector_1\n",
        "    self.batch_op_vector_2=batch_op_vector_2\n",
        "    self.batch_op_vector_3=batch_op_vector_3\n",
        "    self.batch_op_token_idxs_1=batch_op_token_idxs_1\n",
        "    self.batch_op_token_idxs_2=batch_op_token_idxs_2\n",
        "    self.batch_op_token_idxs_3=batch_op_token_idxs_3\n",
        "    self.batch_mask_1=batch_mask_1\n",
        "    self.batch_mask_2=batch_mask_2\n",
        "    self.batch_mask_3=batch_mask_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv7EdP5TSg1i",
        "outputId": "57a4fea1-9a6f-4168-d131-b46b592933be"
      },
      "source": [
        "#tokenized_summaries[0].input_ids\n",
        "a=np.array([list([1,2]) for i in range(2)])\n",
        "a.shape\n",
        "tokenized_summaries_1=tokenized_summaries[2:4]\n",
        "b=np.array([list(tokenized_summary.input_ids) for tokenized_summary in tokenized_summaries_1])\n",
        "b.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5flR8xd5S792",
        "outputId": "2e13bd8d-930e-43d8-fe2d-f7d9f92dea2c"
      },
      "source": [
        "'''\n",
        "run this cell only once.\n",
        "compute BERT based representation of news summary and headline and store it on drive.\n",
        "this will help in faster training, as we don't have to get bert based vector representation of headline and summary during every training iteration. \n",
        "'''\n",
        "batch_start=0\n",
        "batch_end=0\n",
        "end = 32 #len(tokenized_summaries)#32\n",
        "batch_size=16\n",
        "summary_vector=None\n",
        "\n",
        "inputs_input_ids = np.array([list(tokenized_summary.input_ids) for tokenized_summary in tokenized_summaries])\n",
        "inputs_attention_mask = np.array([np.array(tokenized_summary.attention_mask) for tokenized_summary in tokenized_summaries])\n",
        "\n",
        "outputs1_input_ids = np.array([np.array(tokenized_headline.input_ids) for tokenized_headline in tokenized_headlines_1])\n",
        "outputs1_attention_mask = np.array([np.array(tokenized_headline.attention_mask) for tokenized_headline in tokenized_headlines_1])\n",
        "\n",
        "outputs2_input_ids = np.array([np.array(tokenized_headline.input_ids) for tokenized_headline in tokenized_headlines_2])\n",
        "outputs2_attention_mask = np.array([np.array(tokenized_headline.attention_mask) for tokenized_headline in tokenized_headlines_2])\n",
        "\n",
        "outputs3_input_ids = np.array([np.array(tokenized_headline.input_ids) for tokenized_headline in tokenized_headlines_3])\n",
        "outputs3_attention_mask = np.array([np.array(tokenized_headline.attention_mask) for tokenized_headline in tokenized_headlines_3])\n",
        "\n",
        "\n",
        "while batch_end<end:\n",
        "  batch_end=batch_start+batch_size\n",
        "  if batch_end<end:\n",
        "    pass #do nothing\n",
        "  else:\n",
        "    batch_end=end\n",
        "  print('batch_start: ',batch_start,' batch_end: ',batch_end)\n",
        "  summary_batch=inputs_input_ids[batch_start:batch_end]\n",
        "  summary_length_batch=[np.count_nonzero(summary==0) for summary in summary_batch]\n",
        "  attention_mask_summary = inputs_attention_mask[batch_start:batch_end]\n",
        "\n",
        "  headline1_batch=outputs1_input_ids[batch_start:batch_end]\n",
        "  attention_mask_headline1 = outputs1_attention_mask[batch_start:batch_end]\n",
        "\n",
        "  headline2_batch=outputs2_input_ids[batch_start:batch_end]\n",
        "  attention_mask_headline2 = outputs2_attention_mask[batch_start:batch_end]\n",
        "\n",
        "  headline3_batch=outputs3_input_ids[batch_start:batch_end]\n",
        "  attention_mask_headline3 = outputs3_attention_mask[batch_start:batch_end]\n",
        "\n",
        "  summary_batch_t = torch.tensor(summary_batch) \n",
        "  attention_mask_summary_t = torch.tensor(attention_mask_summary)\n",
        "\n",
        "  headline1_batch_t = torch.tensor(headline1_batch) \n",
        "  attention_mask_headline1_t = torch.BoolTensor(attention_mask_headline1)\n",
        "  \n",
        "  headline2_batch_t = torch.tensor(headline2_batch) \n",
        "  attention_mask_headline2_t = torch.BoolTensor(attention_mask_headline2)\n",
        "\n",
        "  headline3_batch_t = torch.tensor(headline3_batch) \n",
        "  attention_mask_headline3_t = torch.BoolTensor(attention_mask_headline3)\n",
        "   \n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(summary_batch_t, attention_mask=attention_mask_summary_t)\n",
        "  summary_batch_vector=last_hidden_states[0]\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(headline1_batch_t, attention_mask=attention_mask_headline1_t)\n",
        "  headline1_batch_vector=last_hidden_states[0]\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(headline2_batch_t, attention_mask=attention_mask_headline2_t)\n",
        "  headline2_batch_vector=last_hidden_states[0]\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(headline3_batch_t, attention_mask=attention_mask_headline3_t)\n",
        "  headline3_batch_vector=last_hidden_states[0]\n",
        "\n",
        "  batch_data=Batch_Data(summary_batch_vector,summary_length_batch,headline1_batch_vector,headline2_batch_vector,headline3_batch_vector,\n",
        "                        headline1_batch_t,headline2_batch_t,headline3_batch_t,attention_mask_headline1_t,attention_mask_headline2_t,attention_mask_headline3_t)\n",
        "  batch_file_path='/content/gdrive/My Drive/Capstone_Project/Data/Bert_vectors/one_to_many_setup/batch_'+str(batch_start)+'_'+str(batch_end)+'.pickle'\n",
        "  with open(batch_file_path, 'wb') as file_handle:\n",
        "    pickle.dump(batch_data, file_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  batch_start=batch_end"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_start:  0  batch_end:  16\n",
            "batch_start:  16  batch_end:  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFnEzNC0wHtQ"
      },
      "source": [
        "'''\n",
        "function for providing emebded representation of BOS token at first timestep of decoding for complete batch\n",
        "'''\n",
        "def get_initial_decoder_ip(batch_size):\n",
        "  sos_token_tensor=torch.tensor([[tokenizer.bos_token_id]])\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(sos_token_tensor)\n",
        "  SOS_token_bert_vector=last_hidden_states[0]\n",
        "  SOS_token_bert_vector=torch.squeeze(SOS_token_bert_vector, 0)\n",
        "  decoder_input = torch.tensor([SOS_token_bert_vector.numpy() for _ in range(batch_size)])\n",
        "  print('decoder_input shape: ',decoder_input.shape)\n",
        "  decoder_input=decoder_input.permute(1,0,2)\n",
        "  print('decoder_input shape: ',decoder_input.shape)\n",
        "  return decoder_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izZUK-y819gJ",
        "outputId": "d3dadb1c-a1b2-41f0-e0f0-e2caf5bde1ae"
      },
      "source": [
        "'''\n",
        "just for testing\n",
        "'''\n",
        "get_initial_decoder_ip(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoder_input shape:  torch.Size([32, 1, 768])\n",
            "decoder_input shape:  torch.Size([1, 32, 768])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
              "         [-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
              "         [-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
              "         ...,\n",
              "         [-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
              "         [-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
              "         [-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiB9tB7ldjJ4"
      },
      "source": [
        "'''\n",
        "GRU based encoder class without any embedding layer (as input will precomputed bert vector representation of news data)\n",
        "'''\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, embbed_dim, hidden_dim, num_layers):\n",
        "       super(Encoder, self).__init__()\n",
        "       #set the encoder input dimesion , embbed dimesion, hidden dimesion, and number of layers \n",
        "       self.hidden_dim = hidden_dim\n",
        "       self.num_layers = num_layers\n",
        "       self.embbed_dim=embbed_dim\n",
        "       #intialize the GRU to take the input dimetion of embbed, and output dimention of hidden and\n",
        "       #set the number of gru layers\n",
        "       self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "  def forward(self, input_seq, input_lengths, hidden=None):\n",
        "    print('inside encoder forward function || input_seq shape: ',input_seq.shape )\n",
        "    print('inside encoder forward function || input_lengths shape: ',input_lengths.shape )\n",
        "    if(hidden!=None):\n",
        "      torch.set_printoptions(threshold=10000)\n",
        "      print('inside encoder forward function || hidden shape: ',hidden )\n",
        "    # Pack padded batch of sequences for RNN module\n",
        "    \n",
        "    # Forward pass through GRU\n",
        "    outputs, hidden = self.gru(input_seq, hidden)\n",
        "    '''\n",
        "    packed = nn.utils.rnn.pack_padded_sequence(input_seq, input_lengths)\n",
        "    outputs, hidden = self.gru(packed, hidden)##TODO \n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "    '''\n",
        "    # Unpack padding\n",
        "    \n",
        "    #print('inside encoder forward function || outputs shape: ',outputs.shape )\n",
        "    #print('inside encoder forward function || hidden shape: ',hidden )\n",
        "    #print('inside encoder forward function || outputs[:, : ,self.hidden_dim:] shape: ',outputs[:, : ,self.hidden_dim:].shape )\n",
        "    # Sum bidirectional GRU outputs\n",
        "    #outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "    # Return output and final hidden state\n",
        "    print('inside encoder forward function || outputs shape: ',outputs.shape )\n",
        "    print('inside encoder forward function || hidden shape: ',hidden.shape )\n",
        "    return outputs, hidden   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M3nsDKvdkAf"
      },
      "source": [
        "'''\n",
        "Luong attention layer\n",
        "'''\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhcaalQLdmzh"
      },
      "source": [
        "'''\n",
        "GRU with Luong Attn based Decoder class \n",
        "'''\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embbed_dim, hidden_size, output_size, num_layers=1 ):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.embbed_dim=embbed_dim\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Define layers\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_size, self.num_layers)\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        #print(\"decoder forward 1 embedded shape: \",embedded.shape)\n",
        "        #embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(input_step, last_hidden)\n",
        "        #print(\"decoder forward 2 rnn_output shape: \",rnn_output.shape)\n",
        "        #print(\"decoder forward 2 hidden shape: \",hidden.shape)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        #print(\"decoder forward 3 attn_weights shape: \",attn_weights.shape)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        #print(\"decoder forward 4 context shape: \",context.shape)\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        #print(\"decoder forward 5 rnn_output.squeeze shape: \",rnn_output.shape)\n",
        "        #print(\"decoder forward 5 context.squeeze shape: \",context.shape)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        #print(\"decoder forward 6 concat_input shape: \",concat_input.shape)\n",
        "        #print(\"decoder forward 6 concat_output shape: \",concat_output.shape)        \n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        #print(\"decoder forward 7 output shape: \",output.shape)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        #print(\"decoder forward 8 output shape: \",output.shape)\n",
        "        # {Return word2 output} {and output} {output} and final hidden state\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1yOxViYdrYH"
      },
      "source": [
        "'''\n",
        "loss function that calculates the average negative log likelihood of the elements that correspond to a 1 in the mask tensor\n",
        "'''\n",
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDiRKtK7dupY"
      },
      "source": [
        "'''\n",
        "function for performing a single training iteration\n",
        "'''\n",
        "def train(input_variable, lengths, target_variable, target_op_token_idxs, mask, max_target_len, encoder, decoder,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip,decoder_ip_initial, teacher_forcing_ratio=1):\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    print('inside train function decoder_ip_initial shape: ',decoder_ip_initial.shape)\n",
        "    decoder_input = decoder_ip_initial#sos token for all the training sample in a given batch\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.num_layers] #this important and handle scenario where no of layer for GRU varries in encoder decoder\n",
        "    #TODO check why 'encoder_hidden[:decoder.n_layers]'? not 'encoder_hidden[:encoder.n_layers]'\n",
        "    #print('inside function train decoder_hidden: ',decoder_hidden.shape)\n",
        "    #print('inside function train encoder_hidden[:encoder.num_layers]: ',encoder_hidden[:encoder.num_layers].shape)\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False #TODO need to work on this\n",
        "    #print('before the decoder forward pass')\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        #iterate through timesteps for decoder \n",
        "        print('teacher forcing will be used for this batch')\n",
        "        for timestep in range(1,max_target_len):\n",
        "            #print('before decoder forward pass: ')\n",
        "            #print('decoder_input shape: ',decoder_input.shape)\n",
        "            #print('decoder_hidden shape: ',decoder_hidden.shape)\n",
        "            #print('encoder_outputs shape: ',encoder_outputs.shape)\n",
        "            print('timestep: ',timestep,' inside train function1: ',decoder_input.shape)\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)#(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Teacher forcing: next input is current target\n",
        "            print('timestep: ',timestep,' inside train function2: ',decoder_input.shape)\n",
        "            decoder_input = torch.unsqueeze(target_variable[timestep],0)#[1,64] use next timestamp token from target seq  as ip to decoder at nexe time step\n",
        "            #print('target_variable[timestep] shape: ',target_variable[timestep].shape)#[64]\n",
        "            #print('target_variable[timestep].view(1, -1) shape: ',target_variable[timestep].view(1, -1).shape)#[1,64]\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_op_token_idxs[timestep], mask[timestep])\n",
        "            print('timestep : ',timestep,' mask_loss: ',mask_loss,' loss: ',loss)\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "            non_padding_token_count=mask[timestep+1].sum()#non_padding_token_count for next timestep\n",
        "            #print('non_padding_token_count: ',non_padding_token_count)\n",
        "            if(non_padding_token_count==0):#all tokens are padding token for next timestep for all records in batches \n",
        "              break\n",
        "    else:\n",
        "        print('teacher forcing won\\'t be used for this batch')\n",
        "        for timestep in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn5D9fEPeij5"
      },
      "source": [
        "'''\n",
        "function for performing a single training iteration\n",
        "'''\n",
        "def train(input_variable, lengths, target_variable1, target_variable2, target_variable3, target_op_token_idxs1, target_op_token_idxs2, target_op_token_idxs3, mask1, mask2,mask3, max_target_len, encoder, decoder1, decoder2, decoder3,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip,decoder_ip_initial, teacher_forcing_ratio=1):\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable1 = target_variable1.to(device)\n",
        "    target_variable2 = target_variable2.to(device)\n",
        "    target_variable3 = target_variable3.to(device)\n",
        "    mask1 = mask1.to(device)\n",
        "    mask2 = mask2.to(device)\n",
        "    mask3 = mask3.to(device)\n",
        "    # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    print('inside train function decoder_ip_initial shape: ',decoder_ip_initial.shape)\n",
        "    decoder_input = decoder_ip_initial#sos token for all the training sample in a given batch\n",
        "    decoder_input1 = decoder_input2 = decoder_input3 = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder1_hidden = decoder2_hidden = decoder3_hidden = encoder_hidden[:decoder.num_layers] #this important and handle scenario where no of layer for GRU varries in encoder decoder\n",
        "    #TODO check why 'encoder_hidden[:decoder.n_layers]'? not 'encoder_hidden[:encoder.n_layers]'\n",
        "    #print('inside function train decoder_hidden: ',decoder_hidden.shape)\n",
        "    #print('inside function train encoder_hidden[:encoder.num_layers]: ',encoder_hidden[:encoder.num_layers].shape)\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False #TODO need to work on this\n",
        "    #print('before the decoder forward pass')\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    # TODO we can get this value from actual op seq \n",
        "    max_target_len=10\n",
        "    if use_teacher_forcing:\n",
        "        #iterate through timesteps for decoder \n",
        "        print('teacher forcing will be used for this batch')\n",
        "        for timestep in range(1,max_target_len):\n",
        "            #print('before decoder forward pass: ')\n",
        "            #print('decoder_input shape: ',decoder_input.shape)\n",
        "            #print('decoder_hidden shape: ',decoder_hidden.shape)\n",
        "            #print('encoder_outputs shape: ',encoder_outputs.shape)\n",
        "            print('timestep: ',timestep,' inside train function1: ',decoder_input.shape)\n",
        "            decoder1_output, decoder1_hidden = decoder(decoder1_input, decoder1_hidden, encoder_outputs) #(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder2_output, decoder2_hidden = decoder(decoder2_input, decoder2_hidden, encoder_outputs)\n",
        "            decoder3_output, decoder3_hidden = decoder(decoder3_input, decoder3_hidden, encoder_outputs)\n",
        "            # Teacher forcing: next input is current target\n",
        "            print('timestep: ',timestep,' inside train function2: ',decoder_input.shape)\n",
        "            decoder1_input = torch.unsqueeze(target_variable1[timestep],0)#[1,64] use next timestamp token from target seq  as ip to decoder at nexe time step\n",
        "            decoder2_input = torch.unsqueeze(target_variable2[timestep],0)\n",
        "            decoder3_input = torch.unsqueeze(target_variable3[timestep],0)\n",
        "            #print('target_variable[timestep] shape: ',target_variable[timestep].shape)#[64]\n",
        "            #print('target_variable[timestep].view(1, -1) shape: ',target_variable[timestep].view(1, -1).shape)#[1,64]\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss1, nTotal = maskNLLLoss(decoder1_output, target_op_token_idxs1[timestep], mask1[timestep])\n",
        "            mask_loss2, nTotal = maskNLLLoss(decoder2_output, target_op_token_idxs2[timestep], mask2[timestep])\n",
        "            mask_loss3, nTotal = maskNLLLoss(decoder3_output, target_op_token_idxs3[timestep], mask3[timestep])\n",
        "\n",
        "            print('timestep : ',timestep,' mask_loss: ',mask_loss,' loss: ',loss)\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "            non_padding_token_count=mask[timestep+1].sum()#non_padding_token_count for next timestep\n",
        "            #print('non_padding_token_count: ',non_padding_token_count)\n",
        "            if(non_padding_token_count==0):#all tokens are padding token for next timestep for all records in batches \n",
        "              break\n",
        "    else:\n",
        "        print('teacher forcing won\\'t be used for this batch')\n",
        "        for timestep in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPZ1n9-F9SgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLnC3cCY9VvV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}